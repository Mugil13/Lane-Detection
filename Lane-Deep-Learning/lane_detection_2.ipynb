{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2840219,
          "sourceType": "datasetVersion",
          "datasetId": 1724942
        }
      ],
      "dockerImageVersionId": 30635,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Advanced Real Time Lane Detection using E-Net+ CNN",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "import kagglehub\n",
        "manideep1108_tusimple_path = kagglehub.dataset_download('manideep1108/tusimple')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "nDWNgbfEuIAN",
        "outputId": "ca25561c-7d0e-447a-aab0-cfa06609cdf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/manideep1108/tusimple?dataset_version_number=5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 9.18G/21.6G [06:56<09:44, 22.9MB/s]"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.cluster import DBSCAN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.loss import _Loss\n",
        "from torch.autograd import Variable\n",
        "import tqdm\n",
        "\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-19T09:10:12.844505Z",
          "iopub.execute_input": "2024-01-19T09:10:12.844877Z",
          "iopub.status.idle": "2024-01-19T09:10:15.937117Z",
          "shell.execute_reply.started": "2024-01-19T09:10:12.844848Z",
          "shell.execute_reply": "2024-01-19T09:10:15.935996Z"
        },
        "trusted": true,
        "id": "iV0lmPhZuIAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LaneDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset_path=\"/kaggle/input/tusimple/TUSimple/train_set\", train=True, size=(512, 256)):\n",
        "        self._dataset_path = dataset_path\n",
        "        self._mode = \"train\" if train else \"eval\"\n",
        "        self._image_size = size # w, h\n",
        "\n",
        "\n",
        "        if self._mode == \"train\":\n",
        "            label_files = [\n",
        "                os.path.join(self._dataset_path, f\"label_data_{suffix}.json\")\n",
        "                for suffix in (\"0313\", \"0531\")\n",
        "            ]\n",
        "        elif self._mode == \"eval\":\n",
        "            label_files = [\n",
        "                os.path.join(self._dataset_path, f\"label_data_{suffix}.json\")\n",
        "                for suffix in (\"0601\",)\n",
        "            ]\n",
        "\n",
        "        self._data = []\n",
        "\n",
        "        for label_file in label_files:\n",
        "            self._process_label_file(label_file)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self._dataset_path, self._data[idx][0])\n",
        "        image = cv2.imread(image_path)\n",
        "        h, w, c = image.shape\n",
        "        #print( \"Image shape : \" + str( image.shape ))\n",
        "        raw_image = image\n",
        "        image = cv2.resize(image, self._image_size, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        image = image[..., None]\n",
        "        lanes = self._data[idx][1]\n",
        "\n",
        "        segmentation_image = self._draw(h, w, lanes, \"segmentation\")\n",
        "        instance_image = self._draw(h, w, lanes, \"instance\")\n",
        "\n",
        "        instance_image = instance_image[..., None]\n",
        "\n",
        "        image = torch.from_numpy(image).float().permute((2, 0, 1))\n",
        "        segmentation_image = torch.from_numpy(segmentation_image.copy())\n",
        "        instance_image =  torch.from_numpy(instance_image.copy()).permute((2, 0, 1))\n",
        "        segmentation_image = segmentation_image.to(torch.int64)\n",
        "\n",
        "        return image, segmentation_image, instance_image, raw_image # 1 x H x W [[0, 1], [2, 0]]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._data)\n",
        "\n",
        "    def _draw(self, h, w, lanes, image_type):\n",
        "        image = np.zeros((h, w), dtype=np.uint8)\n",
        "        for i, lane in enumerate(lanes):\n",
        "            color = 1 if image_type == \"segmentation\" else i + 1\n",
        "            cv2.polylines(image, [lane], False, color, 10)\n",
        "\n",
        "        image = cv2.resize(image, self._image_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        return image\n",
        "\n",
        "    def _process_label_file(self, file_path):\n",
        "        with open(file_path) as f:\n",
        "            for line in f:\n",
        "                info = json.loads(line)\n",
        "                image = info[\"raw_file\"]\n",
        "                lanes = info[\"lanes\"]\n",
        "                h_samples = info[\"h_samples\"]\n",
        "                lanes_coords = []\n",
        "                for lane in lanes:\n",
        "                    x = np.array([lane]).T\n",
        "                    y = np.array([h_samples]).T\n",
        "                    xy = np.hstack((x, y))\n",
        "                    idx = np.where(xy[:, 0] > 0)\n",
        "                    lane_coords = xy[idx]\n",
        "                    lanes_coords.append(lane_coords)\n",
        "                self._data.append((image, lanes_coords))\n",
        "\n",
        "    def _show_images_examples( self , number_sample = 10 ):\n",
        "\n",
        "        # Visualizing some Lane Detection dataset\n",
        "\n",
        "        sns.set_theme()\n",
        "\n",
        "        f, axarr = plt.subplots( number_sample   ,2 , figsize = ( 20 , 30 ))\n",
        "\n",
        "        plt.axis('off')\n",
        "\n",
        "        for i in range( number_sample ):\n",
        "\n",
        "            axarr[ i , 0].imshow(  self.__getitem__( idx = i )[ 3 ].reshape( 720 , 1280 , 3)  )\n",
        "            axarr[ i , 0 ].set_title( \"Lane Image Data No \" + str( i + 1) )\n",
        "            axarr[ i , 0 ].set_axis_off()\n",
        "\n",
        "            axarr[ i , 1 ].imshow(  self.__getitem__( idx = i )[ 2 ].reshape( self._image_size ) )\n",
        "            axarr[ i , 1 ].set_title( \"Lane Image Segmentation Data No \" + str( i + 1) )\n",
        "            axarr[ i , 1 ].set_axis_off()\n",
        "\n",
        "        f.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-19T09:10:15.946536Z",
          "iopub.execute_input": "2024-01-19T09:10:15.947117Z",
          "iopub.status.idle": "2024-01-19T09:10:15.973104Z",
          "shell.execute_reply.started": "2024-01-19T09:10:15.947084Z",
          "shell.execute_reply": "2024-01-19T09:10:15.972283Z"
        },
        "trusted": true,
        "id": "iav3LeYMuIAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InitialBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 bias=False,\n",
        "                 relu=True):\n",
        "        super().__init__()\n",
        "\n",
        "        if relu:\n",
        "            activation = nn.ReLU\n",
        "        else:\n",
        "            activation = nn.PReLU\n",
        "\n",
        "        # Main branch - As stated above the number of output channels for this\n",
        "        # branch is the total minus 3, since the remaining channels come from\n",
        "        # the extension branch\n",
        "        self.main_branch = nn.Conv2d(\n",
        "            in_channels,\n",
        "            out_channels - 1,\n",
        "            kernel_size=3,\n",
        "            stride=2,\n",
        "            padding=1,\n",
        "            bias=bias)\n",
        "\n",
        "        # Extension branch\n",
        "        self.ext_branch = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        # Initialize batch normalization to be used after concatenation\n",
        "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # PReLU layer to apply after concatenating the branches\n",
        "        self.out_activation = activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        main = self.main_branch(x)\n",
        "        ext = self.ext_branch(x)\n",
        "\n",
        "        # Concatenate branches\n",
        "        out = torch.cat((main, ext), 1)\n",
        "\n",
        "        # Apply batch normalization\n",
        "        out = self.batch_norm(out)\n",
        "\n",
        "        return self.out_activation(out)\n",
        "\n",
        "\n",
        "class RegularBottleneck(nn.Module):\n",
        "    def __init__(self,\n",
        "                 channels,\n",
        "                 internal_ratio=4,\n",
        "                 kernel_size=3,\n",
        "                 padding=0,\n",
        "                 dilation=1,\n",
        "                 asymmetric=False,\n",
        "                 dropout_prob=0,\n",
        "                 bias=False,\n",
        "                 relu=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Check in the internal_scale parameter is within the expected range\n",
        "        # [1, channels]\n",
        "        if internal_ratio <= 1 or internal_ratio > channels:\n",
        "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
        "                               \"interval [1, {0}], got internal_scale={1}.\"\n",
        "                               .format(channels, internal_ratio))\n",
        "\n",
        "        internal_channels = channels // internal_ratio\n",
        "\n",
        "        if relu:\n",
        "            activation = nn.ReLU\n",
        "        else:\n",
        "            activation = nn.PReLU\n",
        "\n",
        "        # Main branch - shortcut connection\n",
        "\n",
        "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
        "        # asymmetric convolution, followed by another 1x1 convolution, and,\n",
        "        # finally, a regularizer (spatial dropout). Number of channels is constant.\n",
        "\n",
        "        # 1x1 projection convolution\n",
        "        self.ext_conv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                channels,\n",
        "                internal_channels,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
        "\n",
        "        # If the convolution is asymmetric we split the main convolution in\n",
        "        # two. Eg. for a 5x5 asymmetric convolution we have two convolution:\n",
        "        # the first is 5x1 and the second is 1x5.\n",
        "        if asymmetric:\n",
        "            self.ext_conv2 = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    internal_channels,\n",
        "                    internal_channels,\n",
        "                    kernel_size=(kernel_size, 1),\n",
        "                    stride=1,\n",
        "                    padding=(padding, 0),\n",
        "                    dilation=dilation,\n",
        "                    bias=bias), nn.BatchNorm2d(internal_channels), activation(),\n",
        "                nn.Conv2d(\n",
        "                    internal_channels,\n",
        "                    internal_channels,\n",
        "                    kernel_size=(1, kernel_size),\n",
        "                    stride=1,\n",
        "                    padding=(0, padding),\n",
        "                    dilation=dilation,\n",
        "                    bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
        "        else:\n",
        "            self.ext_conv2 = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    internal_channels,\n",
        "                    internal_channels,\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=1,\n",
        "                    padding=padding,\n",
        "                    dilation=dilation,\n",
        "                    bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
        "\n",
        "        # 1x1 expansion convolution\n",
        "        self.ext_conv3 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                internal_channels,\n",
        "                channels,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=bias), nn.BatchNorm2d(channels), activation())\n",
        "\n",
        "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
        "\n",
        "        # PReLU layer to apply after adding the branches\n",
        "        self.out_activation = activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Main branch shortcut\n",
        "        main = x\n",
        "\n",
        "        # Extension branch\n",
        "        ext = self.ext_conv1(x)\n",
        "        ext = self.ext_conv2(ext)\n",
        "        ext = self.ext_conv3(ext)\n",
        "        ext = self.ext_regul(ext)\n",
        "\n",
        "        # Add main and extension branches\n",
        "        out = main + ext\n",
        "\n",
        "        return self.out_activation(out)\n",
        "\n",
        "\n",
        "class DownsamplingBottleneck(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 internal_ratio=4,\n",
        "                 return_indices=False,\n",
        "                 dropout_prob=0,\n",
        "                 bias=False,\n",
        "                 relu=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Store parameters that are needed later\n",
        "        self.return_indices = return_indices\n",
        "\n",
        "        # Check in the internal_scale parameter is within the expected range\n",
        "        # [1, channels]\n",
        "        if internal_ratio <= 1 or internal_ratio > in_channels:\n",
        "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
        "                               \"interval [1, {0}], got internal_scale={1}. \"\n",
        "                               .format(in_channels, internal_ratio))\n",
        "\n",
        "        internal_channels = in_channels // internal_ratio\n",
        "\n",
        "        if relu:\n",
        "            activation = nn.ReLU\n",
        "        else:\n",
        "            activation = nn.PReLU\n",
        "\n",
        "        # Main branch - max pooling followed by feature map (channels) padding\n",
        "        self.main_max1 = nn.MaxPool2d(\n",
        "            2,\n",
        "            stride=2,\n",
        "            return_indices=return_indices)\n",
        "\n",
        "        # Extension branch - 2x2 convolution, followed by a regular, dilated or\n",
        "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
        "        # of channels is doubled.\n",
        "\n",
        "        # 2x2 projection convolution with stride 2\n",
        "        self.ext_conv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                internal_channels,\n",
        "                kernel_size=2,\n",
        "                stride=2,\n",
        "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
        "\n",
        "        # Convolution\n",
        "        self.ext_conv2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                internal_channels,\n",
        "                internal_channels,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1,\n",
        "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
        "\n",
        "        # 1x1 expansion convolution\n",
        "        self.ext_conv3 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                internal_channels,\n",
        "                out_channels,\n",
        "                kernel_size=1,\n",
        "                stride=1,\n",
        "                bias=bias), nn.BatchNorm2d(out_channels), activation())\n",
        "\n",
        "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
        "\n",
        "        # PReLU layer to apply after concatenating the branches\n",
        "        self.out_activation = activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Main branch shortcut\n",
        "        if self.return_indices:\n",
        "            main, max_indices = self.main_max1(x)\n",
        "        else:\n",
        "            main = self.main_max1(x)\n",
        "\n",
        "        # Extension branch\n",
        "        ext = self.ext_conv1(x)\n",
        "        ext = self.ext_conv2(ext)\n",
        "        ext = self.ext_conv3(ext)\n",
        "        ext = self.ext_regul(ext)\n",
        "\n",
        "        # Main branch channel padding\n",
        "        n, ch_ext, h, w = ext.size()\n",
        "        ch_main = main.size()[1]\n",
        "        padding = torch.zeros(n, ch_ext - ch_main, h, w)\n",
        "\n",
        "        # Before concatenating, check if main is on the CPU or GPU and\n",
        "        # convert padding accordingly\n",
        "        if main.is_cuda:\n",
        "            padding = padding.cuda()\n",
        "\n",
        "        #padding = padding.cpu()\n",
        "\n",
        "        # Concatenate\n",
        "        main = torch.cat((main, padding), 1)\n",
        "\n",
        "        # Add main and extension branches\n",
        "        out = main + ext\n",
        "\n",
        "        return self.out_activation(out), max_indices\n",
        "\n",
        "\n",
        "class UpsamplingBottleneck(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 internal_ratio=4,\n",
        "                 dropout_prob=0,\n",
        "                 bias=False,\n",
        "                 relu=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Check in the internal_scale parameter is within the expected range\n",
        "        # [1, channels]\n",
        "        if internal_ratio <= 1 or internal_ratio > in_channels:\n",
        "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
        "                               \"interval [1, {0}], got internal_scale={1}. \"\n",
        "                               .format(in_channels, internal_ratio))\n",
        "\n",
        "        internal_channels = in_channels // internal_ratio\n",
        "\n",
        "        if relu:\n",
        "            activation = nn.ReLU\n",
        "        else:\n",
        "            activation = nn.PReLU\n",
        "\n",
        "        # Main branch - max pooling followed by feature map (channels) padding\n",
        "        self.main_conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias),\n",
        "            nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        # Remember that the stride is the same as the kernel_size, just like\n",
        "        # the max pooling layers\n",
        "        self.main_unpool1 = nn.MaxUnpool2d(kernel_size=2)\n",
        "\n",
        "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
        "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
        "        # of channels is doubled.\n",
        "\n",
        "        # 1x1 projection convolution with stride 1\n",
        "        self.ext_conv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels, internal_channels, kernel_size=1, bias=bias),\n",
        "            nn.BatchNorm2d(internal_channels), activation())\n",
        "\n",
        "        # Transposed convolution\n",
        "        self.ext_tconv1 = nn.ConvTranspose2d(\n",
        "            internal_channels,\n",
        "            internal_channels,\n",
        "            kernel_size=2,\n",
        "            stride=2,\n",
        "            bias=bias)\n",
        "        self.ext_tconv1_bnorm = nn.BatchNorm2d(internal_channels)\n",
        "        self.ext_tconv1_activation = activation()\n",
        "\n",
        "        # 1x1 expansion convolution\n",
        "        self.ext_conv2 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                internal_channels, out_channels, kernel_size=1, bias=bias),\n",
        "            nn.BatchNorm2d(out_channels), activation())\n",
        "\n",
        "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
        "\n",
        "        # PReLU layer to apply after concatenating the branches\n",
        "        self.out_activation = activation()\n",
        "\n",
        "    def forward(self, x, max_indices, output_size):\n",
        "        # Main branch shortcut\n",
        "        main = self.main_conv1(x)\n",
        "        main = self.main_unpool1(\n",
        "            main, max_indices, output_size=output_size)\n",
        "\n",
        "        # Extension branch\n",
        "        ext = self.ext_conv1(x)\n",
        "        ext = self.ext_tconv1(ext, output_size=output_size)\n",
        "        ext = self.ext_tconv1_bnorm(ext)\n",
        "        ext = self.ext_tconv1_activation(ext)\n",
        "        ext = self.ext_conv2(ext)\n",
        "        ext = self.ext_regul(ext)\n",
        "\n",
        "        # Add main and extension branches\n",
        "        out = main + ext\n",
        "\n",
        "        return self.out_activation(out)\n",
        "\n",
        "\n",
        "class ENet(nn.Module):\n",
        "    def __init__(self, binary_seg, embedding_dim, encoder_relu=False, decoder_relu=True):\n",
        "        super(ENet, self).__init__()\n",
        "\n",
        "        self.initial_block = InitialBlock(1, 16, relu=encoder_relu)\n",
        "\n",
        "        # Stage 1 share\n",
        "        self.downsample1_0 = DownsamplingBottleneck(16, 64, return_indices=True, dropout_prob=0.01, relu=encoder_relu)\n",
        "        self.regular1_1 = RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
        "        self.regular1_2 = RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
        "        self.regular1_3 = RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
        "        self.regular1_4 = RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
        "\n",
        "        # Stage 2 share\n",
        "        self.downsample2_0 = DownsamplingBottleneck(64, 128, return_indices=True, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.regular2_1 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.dilated2_2 = RegularBottleneck(128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.asymmetric2_3 = RegularBottleneck(128, kernel_size=5, padding=2, asymmetric=True, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.dilated2_4 = RegularBottleneck(128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.regular2_5 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.dilated2_6 = RegularBottleneck(128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.asymmetric2_7 = RegularBottleneck(128, kernel_size=5, asymmetric=True, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.dilated2_8 = RegularBottleneck(128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
        "\n",
        "        # stage 3 binary\n",
        "        self.regular_binary_3_0 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.dilated_binary_3_1 = RegularBottleneck(128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.asymmetric_binary_3_2 = RegularBottleneck(128, kernel_size=5, padding=2, asymmetric=True, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.dilated_binary_3_3 = RegularBottleneck(128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.regular_binary_3_4 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.dilated_binary_3_5 = RegularBottleneck(128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.asymmetric_binary_3_6 = RegularBottleneck(128, kernel_size=5, asymmetric=True, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.dilated_binary_3_7 = RegularBottleneck(128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
        "\n",
        "        # stage 3 embedding\n",
        "        self.regular_embedding_3_0 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.dilated_embedding_3_1 = RegularBottleneck(128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.asymmetric_embedding_3_2 = RegularBottleneck(128, kernel_size=5, padding=2, asymmetric=True, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.dilated_embedding_3_3 = RegularBottleneck(128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.regular_embedding_3_4 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.dilated_embedding_3_5 = RegularBottleneck(128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.asymmetric_bembedding_3_6 = RegularBottleneck(128, kernel_size=5, asymmetric=True, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
        "        self.dilated_embedding_3_7 = RegularBottleneck(128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
        "\n",
        "        # binary branch\n",
        "        self.upsample_binary_4_0 = UpsamplingBottleneck(128, 64, dropout_prob=0.1, relu=decoder_relu)\n",
        "        self.regular_binary_4_1 = RegularBottleneck(64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
        "        self.regular_binary_4_2 = RegularBottleneck(64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
        "        self.upsample_binary_5_0 = UpsamplingBottleneck(64, 16, dropout_prob=0.1, relu=decoder_relu)\n",
        "        self.regular_binary_5_1 = RegularBottleneck(16, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
        "        self.binary_transposed_conv = nn.ConvTranspose2d(16, binary_seg, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "\n",
        "        # embedding branch\n",
        "        self.upsample_embedding_4_0 = UpsamplingBottleneck(128, 64, dropout_prob=0.1, relu=decoder_relu)\n",
        "        self.regular_embedding_4_1 = RegularBottleneck(64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
        "        self.regular_embedding_4_2 = RegularBottleneck(64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
        "        self.upsample_embedding_5_0 = UpsamplingBottleneck(64, 16, dropout_prob=0.1, relu=decoder_relu)\n",
        "        self.regular_embedding_5_1 = RegularBottleneck(16, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
        "        self.embedding_transposed_conv = nn.ConvTranspose2d(16, embedding_dim, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial block\n",
        "        input_size = x.size()\n",
        "        x = self.initial_block(x)\n",
        "\n",
        "        # Stage 1 share\n",
        "        stage1_input_size = x.size()\n",
        "        x, max_indices1_0 = self.downsample1_0(x)\n",
        "        x = self.regular1_1(x)\n",
        "        x = self.regular1_2(x)\n",
        "        x = self.regular1_3(x)\n",
        "        x = self.regular1_4(x)\n",
        "\n",
        "        # Stage 2 share\n",
        "        stage2_input_size = x.size()\n",
        "        x, max_indices2_0 = self.downsample2_0(x)\n",
        "        x = self.regular2_1(x)\n",
        "        x = self.dilated2_2(x)\n",
        "        x = self.asymmetric2_3(x)\n",
        "        x = self.dilated2_4(x)\n",
        "        x = self.regular2_5(x)\n",
        "        x = self.dilated2_6(x)\n",
        "        x = self.asymmetric2_7(x)\n",
        "        x = self.dilated2_8(x)\n",
        "\n",
        "        # stage 3 binary\n",
        "        x_binary = self.regular_binary_3_0(x)\n",
        "        x_binary = self.dilated_binary_3_1(x_binary)\n",
        "        x_binary = self.asymmetric_binary_3_2(x_binary)\n",
        "        x_binary = self.dilated_binary_3_3(x_binary)\n",
        "        x_binary = self.regular_binary_3_4(x_binary)\n",
        "        x_binary = self.dilated_binary_3_5(x_binary)\n",
        "        x_binary = self.asymmetric_binary_3_6(x_binary)\n",
        "        x_binary = self.dilated_binary_3_7(x_binary)\n",
        "\n",
        "        # stage 3 embedding\n",
        "        x_embedding = self.regular_embedding_3_0(x)\n",
        "        x_embedding = self.dilated_embedding_3_1(x_embedding)\n",
        "        x_embedding = self.asymmetric_embedding_3_2(x_embedding)\n",
        "        x_embedding = self.dilated_embedding_3_3(x_embedding)\n",
        "        x_embedding = self.regular_embedding_3_4(x_embedding)\n",
        "        x_embedding = self.dilated_embedding_3_5(x_embedding)\n",
        "        x_embedding = self.asymmetric_bembedding_3_6(x_embedding)\n",
        "        x_embedding = self.dilated_embedding_3_7(x_embedding)\n",
        "\n",
        "        # binary branch\n",
        "        x_binary = self.upsample_binary_4_0(x_binary, max_indices2_0, output_size=stage2_input_size)\n",
        "        x_binary = self.regular_binary_4_1(x_binary)\n",
        "        x_binary = self.regular_binary_4_2(x_binary)\n",
        "        x_binary = self.upsample_binary_5_0(x_binary, max_indices1_0, output_size=stage1_input_size)\n",
        "        x_binary = self.regular_binary_5_1(x_binary)\n",
        "        binary_final_logits = self.binary_transposed_conv(x_binary, output_size=input_size)\n",
        "\n",
        "        # embedding branch\n",
        "        x_embedding = self.upsample_embedding_4_0(x_embedding, max_indices2_0, output_size=stage2_input_size)\n",
        "        x_embedding = self.regular_embedding_4_1(x_embedding)\n",
        "        x_embedding = self.regular_embedding_4_2(x_embedding)\n",
        "        x_embedding = self.upsample_embedding_5_0(x_embedding, max_indices1_0, output_size=stage1_input_size)\n",
        "        x_embedding = self.regular_embedding_5_1(x_embedding)\n",
        "        instance_final_logits = self.embedding_transposed_conv(x_embedding, output_size=input_size)\n",
        "\n",
        "        return binary_final_logits, instance_final_logits"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-19T09:10:15.975837Z",
          "iopub.execute_input": "2024-01-19T09:10:15.976144Z",
          "iopub.status.idle": "2024-01-19T09:10:16.043216Z",
          "shell.execute_reply.started": "2024-01-19T09:10:15.976116Z",
          "shell.execute_reply": "2024-01-19T09:10:16.042349Z"
        },
        "trusted": true,
        "id": "_p7jGAhxuIAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiscriminativeLoss(_Loss):\n",
        "    def __init__(self, delta_var=0.5, delta_dist=3,\n",
        "                 norm=2, alpha=1.0, beta=1.0, gamma=0.001,\n",
        "                 device=\"cpu\", reduction=\"mean\", n_clusters=4):\n",
        "        super(DiscriminativeLoss, self).__init__(reduction=reduction)\n",
        "        self.delta_var = delta_var\n",
        "        self.delta_dist = delta_dist\n",
        "        self.norm = norm\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "        self.device = torch.device(device)\n",
        "        self.n_clusters = n_clusters\n",
        "        assert self.norm in [1, 2]\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        assert not target.requires_grad\n",
        "\n",
        "        return self._discriminative_loss(input, target)\n",
        "\n",
        "    def _discriminative_loss(self, input, target):\n",
        "        num_samples=target.size(0)\n",
        "\n",
        "        dis_loss=torch.tensor(0.).to(self.device)\n",
        "        var_loss=torch.tensor(0.).to(self.device)\n",
        "        reg_loss=torch.tensor(0.).to(self.device)\n",
        "        for i in range(num_samples):\n",
        "            clusters=[]\n",
        "            sample_embedding=input[i,:,:,:]\n",
        "            sample_label=target[i,:,:].squeeze()\n",
        "            num_clusters=len(sample_label.unique())-1\n",
        "            vals=sample_label.unique()[1:]\n",
        "            sample_label=sample_label.view(sample_label.size(0)*sample_label.size(1))\n",
        "            sample_embedding=sample_embedding.view(-1,sample_embedding.size(1)*sample_embedding.size(2))\n",
        "            v_loss=torch.tensor(0.).to(self.device)\n",
        "            d_loss=torch.tensor(0.).to(self.device)\n",
        "            r_loss=torch.tensor(0.).to(self.device)\n",
        "            for j in range(num_clusters):\n",
        "                indices=(sample_label==vals[j]).nonzero()\n",
        "                indices=indices.squeeze()\n",
        "                cluster_elements=torch.index_select(sample_embedding,1,indices)\n",
        "                Nc=cluster_elements.size(1)\n",
        "                mean_cluster=cluster_elements.mean(dim=1,keepdim=True)\n",
        "                clusters.append(mean_cluster)\n",
        "                v_loss+=torch.pow((torch.clamp(torch.norm(cluster_elements-mean_cluster)-self.delta_var,min=0.)),2).sum()/Nc\n",
        "                r_loss+=torch.sum(torch.abs(mean_cluster))\n",
        "            for index in range(num_clusters):\n",
        "                for idx,cluster in enumerate(clusters):\n",
        "                    if index==idx:\n",
        "                        continue\n",
        "                    else:\n",
        "                        distance=torch.norm(clusters[index]-cluster)#torch.sqrt(torch.sum(torch.pow(clusters[index]-cluster,2)))\n",
        "                        d_loss+=torch.pow(torch.clamp(self.delta_dist-distance,min=0.),2)\n",
        "            var_loss+=v_loss/num_clusters\n",
        "            dis_loss+=d_loss/(num_clusters*(num_clusters-1))\n",
        "            reg_loss+=r_loss/num_clusters\n",
        "        return self.alpha*(var_loss/num_samples)+self.beta*(dis_loss/num_samples)+self.gamma*(reg_loss/num_samples)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-19T09:10:16.044512Z",
          "iopub.execute_input": "2024-01-19T09:10:16.044778Z",
          "iopub.status.idle": "2024-01-19T09:10:16.061407Z",
          "shell.execute_reply.started": "2024-01-19T09:10:16.044754Z",
          "shell.execute_reply": "2024-01-19T09:10:16.060459Z"
        },
        "trusted": true,
        "id": "CyUyk03iuIAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiscriminativeLoss(_Loss):\n",
        "    def __init__(self, delta_var=0.5, delta_dist=3,\n",
        "                 norm=2, alpha=1.0, beta=1.0, gamma=0.001,\n",
        "                 device=\"cpu\", reduction=\"mean\", n_clusters=4):\n",
        "        super(DiscriminativeLoss, self).__init__(reduction=reduction)\n",
        "        self.delta_var = delta_var\n",
        "        self.delta_dist = delta_dist\n",
        "        self.norm = norm\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.gamma = gamma\n",
        "        self.device = torch.device(device)\n",
        "        self.n_clusters = n_clusters\n",
        "        assert self.norm in [1, 2]\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        assert not target.requires_grad\n",
        "\n",
        "        return self._discriminative_loss(input, target)\n",
        "\n",
        "    def _discriminative_loss(self, input, target):\n",
        "        num_samples=target.size(0)\n",
        "\n",
        "        dis_loss=torch.tensor(0.).to(self.device)\n",
        "        var_loss=torch.tensor(0.).to(self.device)\n",
        "        reg_loss=torch.tensor(0.).to(self.device)\n",
        "        for i in range(num_samples):\n",
        "            clusters=[]\n",
        "            sample_embedding=input[i,:,:,:]\n",
        "            sample_label=target[i,:,:].squeeze()\n",
        "            num_clusters=len(sample_label.unique())-1\n",
        "            vals=sample_label.unique()[1:]\n",
        "            sample_label=sample_label.view(sample_label.size(0)*sample_label.size(1))\n",
        "            sample_embedding=sample_embedding.view(-1,sample_embedding.size(1)*sample_embedding.size(2))\n",
        "            v_loss=torch.tensor(0.).to(self.device)\n",
        "            d_loss=torch.tensor(0.).to(self.device)\n",
        "            r_loss=torch.tensor(0.).to(self.device)\n",
        "            for j in range(num_clusters):\n",
        "                indices=(sample_label==vals[j]).nonzero()\n",
        "                indices=indices.squeeze()\n",
        "                cluster_elements=torch.index_select(sample_embedding,1,indices)\n",
        "                Nc=cluster_elements.size(1)\n",
        "                mean_cluster=cluster_elements.mean(dim=1,keepdim=True)\n",
        "                clusters.append(mean_cluster)\n",
        "                v_loss+=torch.pow((torch.clamp(torch.norm(cluster_elements-mean_cluster)-self.delta_var,min=0.)),2).sum()/Nc\n",
        "                r_loss+=torch.sum(torch.abs(mean_cluster))\n",
        "            for index in range(num_clusters):\n",
        "                for idx,cluster in enumerate(clusters):\n",
        "                    if index==idx:\n",
        "                        continue\n",
        "                    else:\n",
        "                        distance=torch.norm(clusters[index]-cluster)#torch.sqrt(torch.sum(torch.pow(clusters[index]-cluster,2)))\n",
        "                        d_loss+=torch.pow(torch.clamp(self.delta_dist-distance,min=0.),2)\n",
        "            var_loss+=v_loss/num_clusters\n",
        "            dis_loss+=d_loss/(num_clusters*(num_clusters-1))\n",
        "            reg_loss+=r_loss/num_clusters\n",
        "        return self.alpha*(var_loss/num_samples)+self.beta*(dis_loss/num_samples)+self.gamma*(reg_loss/num_samples)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-19T09:10:16.06265Z",
          "iopub.execute_input": "2024-01-19T09:10:16.062923Z",
          "iopub.status.idle": "2024-01-19T09:10:16.079426Z",
          "shell.execute_reply.started": "2024-01-19T09:10:16.062898Z",
          "shell.execute_reply": "2024-01-19T09:10:16.078508Z"
        },
        "trusted": true,
        "id": "q2TyW8vyuIAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(binary_output, instance_output, binary_label, instance_label):\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    binary_loss = ce_loss(binary_output, binary_label)\n",
        "\n",
        "    ds_loss = DiscriminativeLoss(delta_var=0.5, delta_dist=3, alpha=1.0, beta=1.0, gamma=0.001,\n",
        "                                 device= \"cuda\" )#device=\"cpu\")\n",
        "    instance_loss = ds_loss(instance_output, instance_label)\n",
        "\n",
        "    return binary_loss, instance_loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-19T09:10:16.080603Z",
          "iopub.execute_input": "2024-01-19T09:10:16.080917Z",
          "iopub.status.idle": "2024-01-19T09:10:16.091974Z",
          "shell.execute_reply.started": "2024-01-19T09:10:16.080894Z",
          "shell.execute_reply": "2024-01-19T09:10:16.09106Z"
        },
        "trusted": true,
        "id": "CK65aZsZuIAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "import os\n",
        "\n",
        "# Define your LaneDataset class, ENet model, DiscriminativeLoss, and compute_loss as provided earlier\n",
        "\n",
        "# Constants for training\n",
        "BATCH_SIZE = 16\n",
        "LR = 5e-4\n",
        "NUM_EPOCHS = 16 #32\n",
        "\n",
        "# Create the training dataset and dataloader\n",
        "train_dataset = LaneDataset()\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print( \"Is Torch package is CUDA enabled : \" + str( torch.cuda.is_available() ))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Using CPU for easy usage\n",
        "#device = \"cpu\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-19T09:10:16.093276Z",
          "iopub.execute_input": "2024-01-19T09:10:16.096227Z",
          "iopub.status.idle": "2024-01-19T09:10:20.276841Z",
          "shell.execute_reply.started": "2024-01-19T09:10:16.0962Z",
          "shell.execute_reply": "2024-01-19T09:10:20.275835Z"
        },
        "trusted": true,
        "id": "_eWajp-auIAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset._show_images_examples( number_sample= 10 )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-19T09:10:20.278419Z",
          "iopub.execute_input": "2024-01-19T09:10:20.279357Z",
          "iopub.status.idle": "2024-01-19T09:10:27.198726Z",
          "shell.execute_reply.started": "2024-01-19T09:10:20.279319Z",
          "shell.execute_reply": "2024-01-19T09:10:27.197811Z"
        },
        "trusted": true,
        "id": "IJ-zHI9EuIAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the ENet model and move it to the GPU device\n",
        "enet_model = ENet(2, 8)\n",
        "enet_model.to(device)\n",
        "\n",
        "# Define the optimizer\n",
        "params = [p for p in enet_model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.Adam(params, lr=LR, weight_decay=0.0002)\n",
        "\n",
        "# Create a directory for logs\n",
        "log_dir = \"logs\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "# Set up TensorBoard writer\n",
        "writer = SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "# Lists to store losses and accuracies\n",
        "binary_losses_epoch = []\n",
        "instance_losses_epoch = []\n",
        "train_accuracies = []\n",
        "train_f1_score = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    enet_model.train()\n",
        "    losses = []\n",
        "    correct_binary = 0\n",
        "    total_pixels = 0\n",
        "    false_positive_result= 0\n",
        "    true_positive_result = 0\n",
        "\n",
        "    for batch in tqdm.tqdm(train_dataloader):\n",
        "        img, binary_target, instance_target, raw_image = batch\n",
        "        img = img.to(device)\n",
        "        binary_target = binary_target.to(device)\n",
        "        instance_target = instance_target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        binary_logits, instance_emb = enet_model(img)\n",
        "\n",
        "        binary_loss, instance_loss = compute_loss(binary_logits, instance_emb, binary_target, instance_target)\n",
        "        loss = binary_loss + instance_loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append((binary_loss.detach().cpu(), instance_loss.detach().cpu()))\n",
        "\n",
        "        binary_preds = torch.argmax(binary_logits, dim=1)\n",
        "        correct_binary += torch.sum(binary_preds == binary_target).item()\n",
        "\n",
        "        false_positive_result += torch.sum( ( binary_preds == 1 ) & ( binary_target == 0 ) ).item()\n",
        "        true_positive_result += torch.sum( (binary_preds == 1 ) & ( binary_target == 1 ) ).item()\n",
        "        total_pixels += binary_target.numel()\n",
        "\n",
        "    binary_accuracy = correct_binary / total_pixels\n",
        "    binary_total_false = total_pixels - correct_binary\n",
        "    binary_precision = ( true_positive_result )/ ( true_positive_result + false_positive_result )\n",
        "    binary_recall = ( true_positive_result )/ ( true_positive_result + binary_total_false - false_positive_result )\n",
        "    binary_f1_score = 0 if ( binary_recall == 0 ) or ( binary_precision == 0 ) else 2/ ( 1/binary_precision + 1/binary_recall )\n",
        "    train_accuracies.append(binary_accuracy)\n",
        "    train_f1_score.append( binary_f1_score )\n",
        "\n",
        "    mean_losses = np.array(losses).mean(axis=0)\n",
        "    binary_losses_epoch.append(mean_losses[0])\n",
        "    instance_losses_epoch.append(mean_losses[1])\n",
        "\n",
        "    # Log metrics to TensorBoard\n",
        "    writer.add_scalar(\"Binary Loss\", mean_losses[0], epoch)\n",
        "    writer.add_scalar(\"Instance Loss\", mean_losses[1], epoch)\n",
        "    writer.add_scalar(\"Binary Accuracy\", binary_accuracy, epoch)\n",
        "    writer.add_scalar( \"Binary F1 Score\", binary_f1_score , epoch )\n",
        "\n",
        "\n",
        "    # Log details of all layers in histogram format\n",
        "    for name, param in enet_model.named_parameters():\n",
        "        writer.add_histogram(name, param.clone().cpu().data.numpy(), global_step=epoch)\n",
        "\n",
        "    # Print and save results for this epoch\n",
        "    msg = (f\"Epoch {epoch}:\"\n",
        "          f\" Binary Loss = {mean_losses[0]:.4f}, Instance Loss = {mean_losses[1]:.4f}, Binary Accuracy = {binary_accuracy:.4f} , Binary F1- Score = {binary_f1_score:.4f}\" )\n",
        "    print(msg)\n",
        "\n",
        "# Close TensorBoard writer\n",
        "writer.close()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-19T09:10:27.20189Z",
          "iopub.execute_input": "2024-01-19T09:10:27.202204Z"
        },
        "trusted": true,
        "id": "PUEZ7r6WuIAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "\n",
        "# ... (rest of your code)\n",
        "\n",
        "# Plot the training losses and accuracy over epochs\n",
        "plt.figure(figsize=(20, 30))\n",
        "\n",
        "# Plot Binary Segmentation Loss\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(range(NUM_EPOCHS), binary_losses_epoch, label=\"Binary Loss\", color='b', marker='o')\n",
        "plt.scatter([0, NUM_EPOCHS - 1], [binary_losses_epoch[0], binary_losses_epoch[-1]], color='r', marker='o')\n",
        "plt.text(0, binary_losses_epoch[0], f'Start: (0, {binary_losses_epoch[0]:.4f})', verticalalignment='bottom')\n",
        "plt.text(NUM_EPOCHS - 1, binary_losses_epoch[-1], f'End: ({NUM_EPOCHS - 1}, {binary_losses_epoch[-1]:.4f})', verticalalignment='bottom')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Binary Segmentation Loss Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Instance Segmentation Loss\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(range(NUM_EPOCHS), instance_losses_epoch, label=\"Instance Loss\", color='r', marker='o')\n",
        "plt.scatter([0, NUM_EPOCHS - 1], [instance_losses_epoch[0], instance_losses_epoch[-1]], color='r', marker='o')\n",
        "plt.text(0, instance_losses_epoch[0], f'Start: (0, {instance_losses_epoch[0]:.4f})', verticalalignment='bottom')\n",
        "plt.text(NUM_EPOCHS - 1, instance_losses_epoch[-1], f'End: ({NUM_EPOCHS - 1}, {instance_losses_epoch[-1]:.4f})', verticalalignment='bottom')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Instance Segmentation Loss Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Binary Segmentation Accuracy\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(range(NUM_EPOCHS), train_accuracies, label=\"Binary Accuracy\", color='g', marker='o')\n",
        "plt.scatter([0, NUM_EPOCHS - 1], [train_accuracies[0], train_accuracies[-1]], color='r', marker='o')\n",
        "plt.text(0, train_accuracies[0], f'Start: (0, {train_accuracies[0]:.4f})', verticalalignment='bottom')\n",
        "plt.text(NUM_EPOCHS - 1, train_accuracies[-1], f'End: ({NUM_EPOCHS - 1}, {train_accuracies[-1]:.4f})', verticalalignment='bottom')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Binary Segmentation Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"combined_plots_with_start_end_values_on_marker.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "QHjEu4PeuIAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "torch.save(enet_model.state_dict(), \"enet_new_model.pth\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "d3XPrXEwuIAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting training losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, NUM_EPOCHS + 1), binary_losses_epoch, label='Binary Loss')\n",
        "plt.plot(range(1, NUM_EPOCHS + 1), instance_losses_epoch, label='Instance Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Losses')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plotting training accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, NUM_EPOCHS + 1), train_accuracies, label='Binary Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training Binary Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "H7uckluXuIAa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
